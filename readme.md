# TuringChain: Chained Translation and Vector Error Assessment

## 🎯 Project Overview

A complete, modular, multi-agent translation system that processes English sentences through a three-language translation chain (**English → Spanish → Hebrew → English**) and evaluates translation quality using vector-based semantic similarity metrics.

The system simulates a "Turing Machine" for translation, measuring the accumulated error (semantic drift) through the translation chain using cosine distance between sentence embeddings.

---

## 🏗️ System Architecture

### High-Level Architecture Diagram

```
┌─────────────────────────────────────────────────────────────────┐
│                       ORCHESTRATOR                               │
│                (Main Coordinator & Pipeline Manager)             │
└──────────┬──────────────────────────────────────────────────────┘
           │
           ├──► 📝 Sentences Creator Agent
           │    └─► Generates 100 English sentences (10-20 words)
           │        Inspired by Isaac Asimov's "Foundation"
           │        Model: Claude-3-Haiku
           │
           ├──► 🔄 Translation Pipeline (Sequential Chain)
           │    │
           │    ├─► 🇪🇸 Agent 2: English → Spanish Translator
           │    │   └─► Strict system prompt, output translation only
           │    │       Model: Claude-3-Haiku (cost-optimized)
           │    │
           │    ├─► 🇮🇱 Agent 3: Spanish → Hebrew Translator
           │    │   └─► Strict system prompt, output translation only
           │    │       Model: Claude-3-Haiku (cost-optimized)
           │    │
           │    └─► 🇬🇧 Agent 4: Hebrew → English Translator
           │        └─► Strict system prompt, output translation only
           │            Model: Claude-3-Haiku (cost-optimized)
           │
           └──► 📊 Evaluation Agent (Quality Assessment)
                │
                ├─► Vectorization: sentence-transformers (all-MiniLM-L6-v2)
                ├─► Distance Metric: Cosine Distance (scipy)
                ├─► Statistics: Mean, Variance, Std Dev (numpy)
                └─► Visualization: Scatter & Histogram plots (matplotlib)
```

### Data Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                     Translation Chain                            │
└─────────────────────────────────────────────────────────────────┘

Original English Sentence (10-20 words)
    │
    │  [Generated by Sentences Creator Agent]
    │
    ▼
┌─────────────────────────┐
│  Agent 2: EN → ES       │  English → Spanish Translation
└───────────┬─────────────┘
            │ Spanish Text
            ▼
┌─────────────────────────┐
│  Agent 3: ES → HE       │  Spanish → Hebrew Translation
└───────────┬─────────────┘
            │ Hebrew Text
            ▼
┌─────────────────────────┐
│  Agent 4: HE → EN       │  Hebrew → English Translation
└───────────┬─────────────┘
            │ Final Re-translated English
            ▼
┌─────────────────────────────────────────┐
│       Evaluation Agent                  │
├─────────────────────────────────────────┤
│  1. Convert Original & Final to Vectors │
│  2. Calculate Cosine Distance           │
│  3. Compute Statistics (Mean, Variance) │
│  4. Generate Visualization              │
└─────────────────────────────────────────┘
```

---

## 🤖 Agent Descriptions

### 1. **Sentences Creator Agent** (`agent_sentences_creator.py`)

**Role:** Generate diverse English sentences for translation testing

**Specifications:**
- Generates exactly 100 English sentences (configurable)
- Each sentence: 10-20 words
- Thematic inspiration: Isaac Asimov's "Foundation" series
- Implementation: Generator function (yields sentences one at a time)
- API Model: Claude-3-Haiku-20240307

**System Prompt:**
```
You are a creative sentence generator. Generate diverse, grammatically correct
English sentences inspired by the themes, style, and tone of Isaac Asimov's
'Foundation' series. Each sentence must be between 10-20 words long. Output
ONLY the sentences, one per line, with no numbering, explanations, or
additional text.
```

---

### 2. **Agent 2: English → Spanish Translator** (`agent_english_spanish.py`)

**Role:** Translate English text to Spanish with strict output control

**Specifications:**
- Input: English text (string)
- Output: Spanish translation (text only, no commentary)
- API Model: Claude-3-Haiku-20240307
- Max Tokens: 1024

**System Prompt:**
```
You are a translation agent. Your ONLY task is to translate from English to
Spanish. Output ONLY the translated Spanish text with no explanations,
comments, or additional text whatsoever.
```

---

### 3. **Agent 3: Spanish → Hebrew Translator** (`agent_spanish_hebrew.py`)

**Role:** Translate Spanish text to Hebrew with strict output control

**Specifications:**
- Input: Spanish text (string)
- Output: Hebrew translation (text only, no commentary)
- API Model: Claude-3-Haiku-20240307
- Max Tokens: 1024

**System Prompt:**
```
You are a translation agent. Your ONLY task is to translate from Spanish to
Hebrew. Output ONLY the translated Hebrew text with no explanations, comments,
or additional text whatsoever.
```

---

### 4. **Agent 4: Hebrew → English Translator** (`agent_hebrew_english.py`)

**Role:** Translate Hebrew text back to English with strict output control

**Specifications:**
- Input: Hebrew text (string)
- Output: English translation (text only, no commentary)
- API Model: Claude-3-Haiku-20240307
- Max Tokens: 1024

**System Prompt:**
```
You are a translation agent. Your ONLY task is to translate from Hebrew to
English. Output ONLY the translated English text with no explanations,
comments, or additional text whatsoever.
```

---

### 5. **Evaluation Agent** (`agent_evaluation.py`)

**Role:** Assess translation quality using vector-based semantic similarity

**Functions:**

#### **Vectorization (Embeddings)**
- Library: `sentence-transformers`
- Model: `all-MiniLM-L6-v2` (384-dimensional embeddings)
- Converts both original and final sentences to numerical vectors

#### **Distance Measurement**
- Metric: **Cosine Distance**
- Formula: `1 - cosine_similarity`
- Range: 0 (identical meaning) to 1 (completely different)
- Library: `scipy.spatial.distance.cosine`

#### **Statistical Analysis**
- Calculates using `numpy`:
  - **Mean** (average cosine distance)
  - **Variance** (spread of distances)
  - **Standard Deviation**
  - **Min/Max** distances

#### **Visualization**
- Library: `matplotlib`
- Two plots:
  1. **Scatter/Line Plot:** Error per sentence (X: Index, Y: Distance)
  2. **Histogram:** Distribution of distances
- Saves high-resolution PNG (300 DPI)

---

### 6. **Orchestrator** (`orchestrator.py`)

**Role:** Coordinate all agents and manage the complete pipeline

**Responsibilities:**
1. Initialize all agents
2. Manage sentence generation (default: 100, configurable)
3. Process each sentence through the translation chain
4. Collect results as list of tuples: `[(original, final), ...]`
5. Output real-time progress
6. Return results for evaluation

**Synchronization:**
- Sentences are processed immediately after generation
- Enables quasi-parallel pipeline flow
- No waiting for all 100 sentences before starting translation

---

## 📁 Project Structure

```
L14/
├── agent_english_spanish.py       # Agent 2: EN → ES translator
├── agent_spanish_hebrew.py        # Agent 3: ES → HE translator
├── agent_hebrew_english.py        # Agent 4: HE → EN translator
├── agent_sentences_creator.py     # Sentence generator agent
├── agent_evaluation.py            # Quality evaluation agent
├── orchestrator.py                # Main pipeline coordinator
├── run_and_save_with_display.py  # Complete pipeline with display & save
├── test_orchestrator.py          # Quick test (3 sentences)
├── translate_with_claude.py      # Legacy/utility functions
├── PRD.md                        # Product Requirements Document
├── readme.md                     # This file
├── .env                          # API key (not in git)
├── .gitignore                    # Git ignore rules
│
└── Generated Output Files:
    ├── evaluation_metrics.json    # Statistical results
    ├── evaluation_plot.png        # Visualization
    ├── translation_results.json   # All sentence pairs with distances
    └── translation_results.csv    # Indexed sentence pairs (Excel-friendly)
```

---

## 🚀 Installation & Setup

### Prerequisites

- Python 3.8 or higher
- Anthropic API key
- Internet connection

### Installation

```bash
# Clone or download the project
cd L14

# Install required dependencies
pip install anthropic sentence-transformers numpy matplotlib scipy python-dotenv

# Create .env file with your API key
echo "ANTHROPIC_API_KEY=your_api_key_here" > .env
```

---

## 💻 Usage

### Option 1: Full Pipeline with Display and Save (Recommended)

```bash
python run_and_save_with_display.py
```

**What it does:**
- Prompts for number of sentences (default: 100)
- Generates sentences and processes through translation chain
- Prints all results to console
- Displays interactive plot window
- Saves four files: metrics JSON, plot PNG, results JSON, indexed CSV

### Option 2: Quick Test (3 sentences)

```bash
python test_orchestrator.py
```

**What it does:**
- Runs complete pipeline with only 3 sentences
- Faster for testing
- Saves API costs during development

### Option 3: Orchestrator Only

```bash
python orchestrator.py
```

**What it does:**
- Runs translation pipeline only (no evaluation)
- Outputs sentence pairs to console

### Option 4: Programmatic Usage

```python
from orchestrator import run_translation_pipeline
from agent_evaluation import evaluate_translation_quality

# Run translation
api_key = "your_api_key"
translation_results = []

# Manual pipeline execution
# ... (process sentences through agents)

# Evaluate
metrics = evaluate_translation_quality(translation_results)

print(f"Mean Distance: {metrics['mean']}")
print(f"Variance: {metrics['variance']}")
```

---

## 📊 Sample Results (50 Sentences)

### Statistical Metrics

Based on a complete run of 50 sentences through the translation chain:

```
============================================================
TRANSLATION QUALITY METRICS
============================================================
Total Sentences Evaluated: 50

Cosine Distance Statistics:
  Average (Mean):          0.264000
  Variance:                0.024156
  Standard Deviation:      0.155429
  Minimum Distance:        0.002842
  Maximum Distance:        0.768420

Interpretation:
  • Lower cosine distance = Higher semantic similarity
  • Distance of 0 = Identical meaning
  • Distance of 1 = Completely different meaning
============================================================
```

### Quality Assessment

**Mean Distance: 0.264**
- ✅ **Good Quality** - The average cosine distance of ~0.26 indicates that semantic meaning is reasonably well-preserved through the three-translation chain
- Most sentences retained >70% semantic similarity
- The translation pipeline maintains core meaning with some natural variation

**Variance: 0.024**
- ✅ **Moderate Variance** - Shows natural variation in translation quality across different sentence types
- Some sentences translate better than others depending on complexity
- Expected behavior for multi-language chain

**Standard Deviation: 0.155**
- ✅ **Moderate Distribution** - Most sentences fall within ±0.15 of the mean
- Indicates variable but acceptable translation performance
- Some outliers exist (very good or challenging translations)

### Sample Sentence Comparisons

Examples from the actual 50-sentence run (showing various quality levels):

| # | Original English | Final Re-translated English | Distance |
|---|-----------------|---------------------------|----------|
| 1 | The Galactic Empire spanned millions of worlds across the spiral arms of the galaxy. | The galactic empire spanned millions of worlds in the spiral arms of the galaxy. | 0.003 |
| 5 | Hari Seldon's mathematical framework predicted societal collapse with unprecedented precision and statistical certainty. | Hari Seldon's mathematical model predicted the collapse of society with unprecedented precision and statistical certainty. | 0.092 |
| 12 | The Encyclopedia Project disguised the Foundation's true purpose from imperial authorities and potential enemies. | The Encyclopedia project concealed the true purpose of the Foundation from imperial authorities and potential enemies. | 0.134 |
| 25 | Terminus developed advanced technology while facing threats from neighboring kingdoms seeking territorial expansion. | Terminus developed advanced technology while confronting threats from neighboring kingdoms seeking territorial expansion. | 0.051 |
| 38 | The Mule's mental powers disrupted Seldon's carefully calculated predictions for the Foundation's future. | The Mule's mental powers altered Seldon's carefully calculated predictions for the future of the Foundation. | 0.613 |
| 42 | Second Foundation agents manipulated events from the shadows to preserve psychohistory's grand design. | Second foundation agents manipulated events from the shadows to maintain the great design of psychohistory. | 0.077 |
| 50 | Galactic civilization teetered on the brink of chaos as predicted by psychohistorical mathematics. | Galactic civilization balanced on the brink of chaos as predicted by psychohistorical mathematics. | 0.069 |

### Visualization

The system generates two plots:

#### **Plot 1: Cosine Distance per Sentence**
- Scatter plot showing error for each of 50 sentences
- Blue dots: Individual cosine distances
- Red dashed line: Mean (0.264)
- Red shaded area: ±1 standard deviation band
- X-axis: Sentence Index (1-50)
- Y-axis: Cosine Distance (0.0-0.8)

#### **Plot 2: Distribution Histogram**
- Green bars: Frequency distribution of distances
- Red dashed line: Mean (0.264)
- Most values cluster around 0.10-0.40 range
- Shows natural variation in translation quality

![Translation Quality Evaluation Plot](evaluation_plot.png)

*Figure: Translation quality evaluation showing cosine distance per sentence (top) and distribution histogram (bottom)*

---

## 🔬 Technical Details

### Embedding Model

**Model:** `all-MiniLM-L6-v2`
- Type: Sentence Transformer
- Dimensions: 384
- Training: Optimized for semantic similarity tasks
- Performance: High quality, fast inference
- Size: ~80MB

### API Configuration

**Model:** Claude-3-Haiku-20240307
- Fastest and most cost-effective Claude model
- Sufficient quality for translation tasks
- Max tokens: 1024 per request
- Temperature: Default (0.7)

### Cost Estimation (100 Sentences)

Approximate API costs for 100 sentences:

| Component | API Calls | Tokens/Call | Cost Estimate |
|-----------|-----------|-------------|---------------|
| Sentence Generation | 1 | ~2000 | $0.02 |
| EN → ES (100x) | 100 | ~150 | $0.12 |
| ES → HE (100x) | 100 | ~150 | $0.12 |
| HE → EN (100x) | 100 | ~150 | $0.12 |
| **Total** | **301** | **~17,000** | **~$0.38** |

*Costs are approximate based on Claude-3-Haiku pricing as of October 2025*

---

## 📈 Output Files

### 1. `evaluation_metrics.json`

Contains statistical results:

```json
{
  "total_sentences": 50,
  "mean_cosine_distance": 0.264000,
  "variance": 0.024156,
  "standard_deviation": 0.155429,
  "min_distance": 0.002842,
  "max_distance": 0.768420,
  "interpretation": {
    "note": "Lower cosine distance = Higher semantic similarity",
    "perfect_match": 0.0,
    "completely_different": 1.0
  }
}
```

### 2. `evaluation_plot.png`

High-resolution (300 DPI) visualization showing:
- Scatter plot with line (error per sentence)
- Histogram (distribution of errors)
- Mean line and standard deviation shading

### 3. `translation_results.json`

Complete dataset with all sentence pairs:

```json
{
  "total_sentences": 50,
  "pipeline": "English → Spanish → Hebrew → English",
  "results": [
    {
      "index": 1,
      "original": "The Galactic Empire spanned millions...",
      "final_translated": "The galactic empire spanned millions...",
      "cosine_distance": 0.002842
    },
    ...
  ]
}
```

### 4. `translation_results.csv`

Excel-friendly CSV file with indexed sentence pairs:

```csv
Index,Original English,Final Re-translated English
1,"The Galactic Empire spanned millions...","The galactic empire spanned millions..."
2,"Hari Seldon foresaw the fall...","Hari Seldon predicted the fall..."
...
```

Perfect for opening in Excel, Google Sheets, or any spreadsheet application.

---

## 🛠️ Troubleshooting

### Common Issues

**1. ModuleNotFoundError: No module named 'sentence_transformers'**
```bash
pip install sentence-transformers
```

**2. API Key Error**
```bash
# Make sure .env file exists with:
ANTHROPIC_API_KEY=your_actual_api_key
```

**3. Model Download Issues**
- First run downloads the embedding model (~80MB)
- Requires internet connection
- Models cached in `~/.cache/torch/sentence_transformers/`

**4. Plot Not Displaying**
```python
# Make sure matplotlib backend is configured
import matplotlib
matplotlib.use('TkAgg')  # or 'Qt5Agg'
```

---

## 📚 Dependencies

```txt
anthropic>=0.18.0
sentence-transformers>=5.0.0
numpy>=1.24.0
matplotlib>=3.7.0
scipy>=1.10.0
python-dotenv>=1.0.0
torch>=2.0.0  # Required by sentence-transformers
transformers>=4.30.0  # Required by sentence-transformers
```

Install all with:
```bash
pip install anthropic sentence-transformers numpy matplotlib scipy python-dotenv
```

---

## 🎓 Academic Context

This project demonstrates:
- **Multi-agent systems** coordination
- **Natural Language Processing** with embeddings
- **Semantic similarity** measurement
- **Error propagation** through translation chains
- **Statistical analysis** of linguistic transformations
- **Modular software architecture**

---

## 📄 License

This project is part of an academic assignment. All rights reserved.

---

## 👤 Author

AI Expert Course - Koby Lev

---

## 📞 Support

For issues or questions:
1. Check the PRD.md for detailed specifications
2. Review troubleshooting section above
3. Verify all dependencies are installed
4. Ensure API key is correctly configured

---

*Last Updated: 29 October 2025*
